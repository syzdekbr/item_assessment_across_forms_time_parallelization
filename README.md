# item_assessment_across_forms_time_parallelization
Test interaction of exam items and exam form, consideration of big data input methods, using sampling and replication with big data, functions to extract significant effects from significant models, and conduct post-hoc analyses, with plots.

Rmarkdown report examined the variation of a select number of test items across examinations and time. The code was generalized to allow any vector of items to be input and to run this analysis. A good use case for this process is to analyze items to be considered for inclusion in an exam based on past performance on previous exams.   This analysis considered methods for extracting data using several methods to optimize speed, including parallelization.  As there were a large number of data and analytic methods involved a large number of contrasts, sampling the data and conducting analysis repeatedly was determined to be the best approach to manage these complications. Sample size calculations were performed using simulation of the proposed models for analyzing exam and year interaction with items to determine sample size and number of repetitions necessary to achieve desired power.  Likelihood ratio tests between models with interaction terms and models with interactions removed were conducted to identify if there were significant interactions between items and exams and year. For models with significant interaction effects, specific interaction terms that were significant were extracted. Post-hoc comparisons of these items showed where differences occurred.
